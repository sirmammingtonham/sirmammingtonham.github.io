<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>futureMAG - Ethan Joseph</title>
		<link rel="apple-touch-icon" sizes="180x180" href="../images/favicon/apple-touch-icon.png">
		<link rel="icon" type="image/png" sizes="32x32" href="../images/favicon/favicon-32x32.png">
		<link rel="icon" type="image/png" sizes="16x16" href="../images/favicon/favicon-16x16.png">
		<link rel="manifest" href="../images/favicon/site.webmanifest">
		<link rel="mask-icon" href="../images/favicon/safari-pinned-tab.svg" color="#5bbad5">
		<link rel="shortcut icon" href="../images/favicon/favicon.ico">
		<meta name="msapplication-TileColor" content="#da532c">
		<meta name="msapplication-config" content="../images/favicon/browserconfig.xml">
		<meta name="theme-color" content="#ffffff">
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../assets/css/main.css" />
		<noscript><link rel="stylesheet" href="../assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<img src="../images/science-book.svg" class="icon">
						<h1>futureMAG</h1>
						<p>AI Generated Magazine</p>
						<p style="font-size:100%; padding-bottom:0.5em;">By robots, for robots. Jk its for humans.</p>
						<!-- <p style="font-size:100%; padding-bottom:0.5em;"><i>"The Future of Storytelling"</i></p> -->
						<ul class="icons">

							<li>
								<a href="https://github.com/sirmammingtonham/futureMAG" target="_blank" class="icon brands fa-github alt">
									<span class="label">Github</span>
								</a>
							</li>
							<li>
								<a href="https://medium.com/futuremag" target="_blank" class="icon solid fa-arrow-right alt">
									<span class="label">futureMAG</span>
								</a>
							</li>
						</ul>
					</header>

				<!-- Main -->
					<div id="main">

						<!-- Content -->
							<section id="content" class="main">
								<span class="image main"><a href="https://medium.com/futuremag" target="_blank"><img src="../images/futureMAG.jpg"/></a></span>
								<h2>futureMAG</h2>
								<h3>The Future of Storytelling — Told by AI.</h3>
								<p>
									futureMAG is an NLP project which uses OpenAI's <a href="https://openai.com/blog/better-language-models/">GPT-2 model</a> (345M parameter version) to generate synthetic yet somewhat believable articles for a publication on medium.com. These articles are then cleaned up and automatically published using a python script and Medium.com's publishing api.
								</p>
								<hr />
								<h2><strong>Details</strong></h2>
								<p>
									This project was designed to be a sort of experiment in what magazines of the future would look like. Essentially, I wanted articles about the future and technology to be written and published by that "futuristic technology."
								</p>
								<p>
									The project had 4 main steps: 
									<ol>
										<li>
											Scrape articles from tech/futuristic publications (namely <a href="https://medium.com/one-zero" target="_blank">OneZero</a> and <a href="https://medium.com/short-sci-fi-stories" target="_blank">Futura</a>) and clean them up until we have a decent dataset to finetune the language model. (Details under <strong>Dataset Generation</strong>.)
										</li>
										<li>
											Finetune the language model being careful not to overfit it. (I used the <a href="https://github.com/minimaxir/gpt-2-simple">gpt-2-simple</a> library for training.)
										</li>
										<li>
											Generate articles using the finetuned model. (Details under <strong>Article Generation</strong>.)
										</li>
										<li>
											Create a short program that cleans up the generated text and retrieves images from unsplash.com to serve as the hero images for the article. Then use Medium.com's web api to publish the article to the futureMAG publication.
										</li>
									</ol>
								</p>
								<hr />
								<h3><strong>Dataset Generation</strong></h3>
								<p>
									I ran into a few issues while trying to generate a dataset:
									<ol>
										<li>
											Medium loads articles on its webpages with javascript, so there was no simple way to retrieve all the articles under a publication using something like BeautifulSoup.
										</li>
										<li>
											I had to find some way to clean them up in a way that allowed the neural net to learn an accurate representation of the style, while also trying to minimize clean up work later.
										</li>
									</ol>
								</p>
								<p>
									In order to generate a list of articles, I used Selenium and Chrome driver. Essentially I opened the "latest" page of the publication with selenium, then told it to scroll to the end of the page so medium would load more articles. Once no more articles were being loaded, I retrieved the urls and compiled them into a file.
								</p>
								<p>
									At first, I used BeautifulSoup to download the articles, however this method only retrieved the raw text from the article. In order to minimize post processing, I realized I could train the GPT-2 model on a markdown representation of the articles, with the goal of having the model generate most of the formatting (and minimizing post-processing later). In order to do that, I modified a version of the <a href="https://github.com/xdamman/mediumexporter">mediumexporter</a> library, which was written in javascript and retrieved the articles then converted them to a markdown format.
								</p>
								<h3><strong>Article Generation</strong></h3>
								<p>
									The biggest issue I had with GPT-2 is that it was designed to generate texts only 1028 tokens long, which on average is about a paragraph (but I needed whole articles). In order to work around this, I modified minimaxir's generation script to feed half of the previously generated text as context for the next generation. This allowed me to chain together generations from the language model until it arrived at a full length article. The main issue with this method is that the context from two generations is lost (since we are only passing in context from the most recent generation), which can sometimes lead to the network changing attention quickly and writing about a completely different topic halfway through the article. But when it works, it works lol.
								</p>
								<p>
									If you want to check out the code, click the github link below, or click the button to go to futureMAG!
								</p>
								<hr />
								<ul class="actions special">
									<li><a href="https://medium.com/futuremag" class="button primary" target="_blank">futureMAG</a></li>
								</ul>
								<a class="embedly-card" data-card-controls="0" href="https://github.com/sirmammingtonham/futureMAG">sirmammingtonham/futureMAG</a>
								<script async src="//cdn.embedly.com/widgets/platform.js" charset="UTF-8"></script>
							</section>

					</div>

				<!-- Footer -->
					<footer id="footer">
						<p class="copyright">&copy; AI that was too powerful to release. Until it wasn't...<br>(not that i can fit it on my gpu anyway)</p>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="../assets/js/jquery.min.js"></script>
			<script src="../assets/js/jquery.scrollex.min.js"></script>
			<script src="../assets/js/jquery.scrolly.min.js"></script>
			<script src="../assets/js/browser.min.js"></script>
			<script src="../assets/js/breakpoints.min.js"></script>
			<script src="../assets/js/util.js"></script>
			<script src="../assets/js/main.js"></script>

	</body>
</html>